{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e232f9a-6a7a-49cf-8caa-d45aa81e9111",
   "metadata": {},
   "source": [
    "# Prepare a CSV file for the OWG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a17dc-456c-4269-9e2f-659b54b3a755",
   "metadata": {},
   "source": [
    "This notebook contains code as a function and a walk through for creating a csv file that can be use in optical wave gauging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1253f43-1469-4d30-b07d-d87511fdf51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and libs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import calendar\n",
    "from scipy import interpolate\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30abc9df-d19d-4062-b93c-05d51502eca7",
   "metadata": {},
   "source": [
    "\n",
    "## Read data\n",
    "\n",
    "Data comes from two sources:  \n",
    "* 1. NDBC standard meteorlogical observation archives, found [here](https://www.ndbc.noaa.gov/) \n",
    "* 2. Archived ReCON imagery, partial records can be scraped from the [website](https://www.glerl.noaa.gov/metdata/) or accessed from GLERL's network\n",
    "\n",
    "\n",
    "This data must be joined so that each webcam image is associated with meterological observations taken no later than 30 minutes before or after the image was taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6eb19735-f13a-4ddf-aae3-23a2426b71e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare the buoy data for joining\n",
    "\n",
    "def readwavetxt(fn, target):\n",
    "    '''Take a  txt file and return a dataframe\n",
    "    \n",
    "    fn: filename and location of .txt file\n",
    "    target: attribute that the owg will be predicting'''\n",
    "    df = pd.read_csv(fn, skiprows=range(1,2), delim_whitespace = True, \\\n",
    "                    parse_dates={'date':[0,1,2,3,4]}, keep_date_col=False)\n",
    "\n",
    "    # Transfer data in \"date\" column to a column where it is stored as a datetime object\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format = '%Y %m %d %H %M',utc=True)\n",
    "    df = df.drop(df.columns[[0,1,2,3,6,8,9,10,11,12, 13]], axis = 1)\n",
    "    \n",
    "    # calculate unix datetime\n",
    "    df['epoch']=(df['datetime'] - pd.Timestamp(\"1970-01-01\",tz='utc')) // pd.Timedelta('1s')\n",
    "    \n",
    "    # remove data with NaN values \n",
    "    # if target == \"WVHT\":\n",
    "    #     df = df[df.WVHT != 99.0]\n",
    "    # if target == \"DPD\":\n",
    "    #      df = df[df['DPD'] < 99.0]\n",
    "    # if target == \"MWD\":\n",
    "    #     df = df[df['MWD'] < 999]\n",
    "    \n",
    "    print(df)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a2fbeabe-17c5-461a-8ce3-8dbfdb8e130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete csv\n",
    "\n",
    "def waveframetocsv(fn, target, csvfile, directory, localtimezone):\n",
    "    '''\n",
    "    This function takes a txt file and folder of OWG images and combines the data into a csv file that can be fed into the OWG. \n",
    "    \n",
    "    fn: filename and location of .txt file\n",
    "    target: attribute that the owg will be predicting\n",
    "    csvfile:the name of the csvfile being created\n",
    "    directory: the directory of images that have been prepped for OWG filtering\n",
    "    localtimezone: the timezone code in pytz that the images were taken in\n",
    "    '''\n",
    "    \n",
    "    #counters for debugging and perfomance info\n",
    "    initaladdcounter = 0\n",
    "    rangecounter = 0\n",
    "    successcounter = 0\n",
    "    failcounter = 0\n",
    "    timecounter = 0\n",
    "    outofrangecounter = 0\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(fn, skiprows=range(1,2), delim_whitespace = True, \\\n",
    "                    parse_dates={'date':[0,1,2,3,4]}, keep_date_col=False)\n",
    "\n",
    "    # Transfer data in \"date\" column to a column where it is stored as a datetime object\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format = '%Y %m %d %H %M',utc=True)\n",
    "    df = df.drop(df.columns[[0,1,2,3,6,8,9,10,11,12, 13]], axis = 1)\n",
    "    \n",
    "    # calculate unix datetime\n",
    "    df['epoch']=(df['datetime'] - pd.Timestamp(\"1970-01-01\",tz='utc')) // pd.Timedelta('1s')\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    # delete the csv file if it exsists\n",
    "    try:\n",
    "        print (\"Overwriting csv file\")\n",
    "        os.remove(csvfile)\n",
    "        owgframe = pd.DataFrame({\"id\":[], \"H\":[], \"T\":[], \"MWDIR\":[]})\n",
    "    except:\n",
    "        print(\"couldn't find file, making new one\")\n",
    "        # create csv file that will be appended to by loop\n",
    "        owgframe = pd.DataFrame({\"id\":[], \"H\":[], \"T\":[], \"MWDIR\":[]})\n",
    "\n",
    "    #loop through directory and extract unix timestamp\n",
    "    for filename in os.listdir(directory):\n",
    "        # Use string slicing to remove .jpg from filename\n",
    "        size = len(filename)\n",
    "        fn = filename[:size - 4]\n",
    "       \n",
    "        \n",
    "        #get time from filename\n",
    "        local = pytz.timezone(localtimezone)\n",
    "        naive = datetime.datetime.strptime(fn, \"%Y%m%d%H%M\")\n",
    "        local_dt = local.localize(naive)\n",
    "        utc_dt = local_dt.astimezone(pytz.utc)\n",
    "        utime = calendar.timegm(utc_dt.timetuple())\n",
    "        \n",
    "        # combine datasets\n",
    "        try:\n",
    "            if utime >= df['epoch'].iat[0]:\n",
    "                result_index = df['epoch'].sub(utime).abs().idxmin()\n",
    "                result = df['epoch'].iat[result_index]\n",
    "                rangecounter = rangecounter + 1\n",
    "                \n",
    "                if abs(utime - result) <= 1800:\n",
    "                    initaladdcounter = initaladdcounter + 1\n",
    "                    stageframe = {\"id\":filename, \"H\": df['WVHT'].iat[result_index], \"T\": df['DPD'].iat[result_index], \"MWDIR\":df['MWD'].iat[result_index]}\n",
    "                    owgframe = owgframe.append(stageframe, ignore_index = True)\n",
    "                    \n",
    "                    if target == \"WVHT\":\n",
    "                        owgframe = owgframe[owgframe.H != 99.0]\n",
    "                    if target == \"DPD\":\n",
    "                        owgframe = owgframe[owgframe.DPD != 99.0]\n",
    "                    if target == \"MWD\":\n",
    "                        owgframe = owgframe[owgframe.MWDIR != 999]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    timecounter = timecounter + 1\n",
    "            else:\n",
    "                outofrangecounter = outofrangecounter + 1\n",
    "        except:\n",
    "            failcounter = failcounter + 1\n",
    "    added = len(owgframe.index)\n",
    "    owgframe.to_csv(csvfile, index = False)    \n",
    "    \n",
    "    print (\"you have {} images during buoy deployment\".format(rangecounter))\n",
    "    print (\"{} images outside of buoy deployment\".format(outofrangecounter))\n",
    "    print (\"{} images do not have data within 30 minutes\".format(timecounter))\n",
    "    print (\"{} images had NAN data from buoy\".format(initaladdcounter-int(added)))\n",
    "    print (\"{} images failed\".format(failcounter))\n",
    "    print (\"{} images added to {}\".format(added, csvfile))\n",
    "    \n",
    "   \n",
    "    \n",
    "    return  \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "98ade2ad-6110-4d84-aaf2-c96cf5837cd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.41   2.68   24 2021-05-08 22:00:00+00:00  1620511200\n",
      "1      0.39   2.78   63 2021-05-08 22:10:00+00:00  1620511800\n",
      "2      0.39   2.45   65 2021-05-08 22:20:00+00:00  1620512400\n",
      "3      0.36   2.62   84 2021-05-08 22:30:00+00:00  1620513000\n",
      "4      0.34   2.73   86 2021-05-08 22:40:00+00:00  1620513600\n",
      "...     ...    ...  ...                       ...         ...\n",
      "20897  0.28   2.11  224 2021-10-14 11:30:00+00:00  1634211000\n",
      "20898  0.27   2.33  217 2021-10-14 11:40:00+00:00  1634211600\n",
      "20899  0.25   2.32  215 2021-10-14 11:50:00+00:00  1634212200\n",
      "20900  0.23   2.34  227 2021-10-14 12:10:00+00:00  1634213400\n",
      "20901  0.23  99.00  216 2021-10-14 12:20:00+00:00  1634214000\n",
      "\n",
      "[20902 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021.txt\"\n",
    "target = \"WVHT\"\n",
    "waves = readwavetxt(fn, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d091f535-449b-4b14-850e-ae6785a4e591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.41   2.68   24 2021-05-08 22:00:00+00:00  1620511200\n",
      "1      0.39   2.78   63 2021-05-08 22:10:00+00:00  1620511800\n",
      "2      0.39   2.45   65 2021-05-08 22:20:00+00:00  1620512400\n",
      "3      0.36   2.62   84 2021-05-08 22:30:00+00:00  1620513000\n",
      "4      0.34   2.73   86 2021-05-08 22:40:00+00:00  1620513600\n",
      "...     ...    ...  ...                       ...         ...\n",
      "20897  0.28   2.11  224 2021-10-14 11:30:00+00:00  1634211000\n",
      "20898  0.27   2.33  217 2021-10-14 11:40:00+00:00  1634211600\n",
      "20899  0.25   2.32  215 2021-10-14 11:50:00+00:00  1634212200\n",
      "20900  0.23   2.34  227 2021-10-14 12:10:00+00:00  1634213400\n",
      "20901  0.23  99.00  216 2021-10-14 12:20:00+00:00  1634214000\n",
      "\n",
      "[20902 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "you have 1130 images during buoy deployment\n",
      "412 images outside of buoy deployment\n",
      "45 images do not have data within 30 minutes\n",
      "43 images had NAN data from buoy\n",
      "0 images failed\n",
      "1042 images added to C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2021\"\n",
    "waveframetocsv(fn, target, csvfile, directory, \"America/Chicago\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
