{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420be7b7",
   "metadata": {},
   "source": [
    "\n",
    "# Prepare ReCON Webcam Images for Optical Wave Gauging\n",
    "\n",
    "This code was written by [Nicholas Catanzaro](https://github.com/ncata/GLERL_contract) for NOAA GLERL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea086b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Functionality\n",
    "This notebook is a work in progress. It contains code for functions that will be put into a .py file. It is arranged to walk the reader through the author's logic and allow a variety of people who may be unfamiliar with the OWG or Jupyter to implement the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1253f43-1469-4d30-b07d-d87511fdf51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and libs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import calendar\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pytz\n",
    "from PIL import Image\n",
    "from distutils.dir_util import copy_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef610246",
   "metadata": {},
   "source": [
    "### Augment and QC Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39477abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepowgimgs(year, directory, arrayshape, resolution, trial, viewlist):\n",
    "    '''Create a new directory for images in each view and run QC and primary augmentation before interpolation and then model \n",
    "    training, validation, or testing. version 2.5\n",
    "    \n",
    "    Year: the target year of images, \n",
    "    directory: where the year files are stored,\n",
    "    resolution:the resolution the images will be reduced to, \n",
    "    trial: the name of the trial that these inputs are associated with. \n",
    "    viewlist: a list of the view numbers found in the target year folder\n",
    "    '''\n",
    "    start = time.time()\n",
    "    #set counters \n",
    "    counter = 0\n",
    "    nightcounter = 0\n",
    "    failcounter = 0\n",
    "    \n",
    "    # create a new directory for images\n",
    "    foldername = \"/{}_imgprep\".format(str(year))\n",
    "    newdir = directory+foldername+\"{}\".format(trial)\n",
    "    try:\n",
    "        shutil.rmtree(newdir)\n",
    "        print(\"Folder found: deleting contents\")\n",
    "        print(\"Creating folder\")\n",
    "        os.mkdir(newdir)\n",
    "    except:\n",
    "        print(\"Creating folder\")\n",
    "        #os.mkdir(newdir)\n",
    "\n",
    "    # copy files into new directory, this can take a while\n",
    "    print(\"Moving Files\")\n",
    "    copy_tree(directory, newdir)\n",
    "    \n",
    "    # seperate the views into different folders within the directory\n",
    "    viewdirs = []\n",
    "    for view in viewlist:\n",
    "        print(\"Seperating View {}\".format(view))\n",
    "        viewpath = newdir+\"/view{}\".format(view)\n",
    "        viewdirs.append(viewpath)\n",
    "        os.mkdir(viewpath) \n",
    "    \n",
    "    \n",
    "    for viewpath in viewdirs:\n",
    "        print (\"Moving images to {}\".format(viewpath))\n",
    "        # move images into views\n",
    "        for filename in os.listdir(newdir):\n",
    "            if filename[-5] == viewpath[-1]:\n",
    "                os.rename(newdir+\"/{}\".format(filename), viewpath+\"/{}\".format(filename.replace(filename[13:16],\"\")))   \n",
    "        \n",
    "        # edit images from desired view into cropped lower resolution grayscale and store in new folder\n",
    "        print (\"Augmenting and filtering imgaes in {}\".format(viewpath))\n",
    "        for filename in os.listdir(viewpath):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                image = Image.open(viewpath+\"/{}\".format(filename)).convert(\"L\")\n",
    "            \n",
    "                # select target portion of image to make it square\n",
    "                bwarray = np.array(image) \n",
    "                small = bwarray[arrayshape]\n",
    "                \n",
    "                # change image resoltuion\n",
    "                img = Image.fromarray(small)\n",
    "                resize = (resolution, resolution)\n",
    "                smaller = img.resize(resize)\n",
    "               \n",
    "                #Get QC metrics\n",
    "                avgintensity = np.mean(np.asarray(smaller))\n",
    "                \n",
    "                # perform QC\n",
    "                if avgintensity < 85:\n",
    "                    os.remove(viewpath+\"/\"+filename)\n",
    "                    failcounter = failcounter + 1\n",
    "                else:\n",
    "                    # save images to OWG directory\n",
    "                    try:\n",
    "                        counter = counter + 1\n",
    "                        owgimage = smaller.save(viewpath+\"/{}\".format(filename))\n",
    "                    except IOError:\n",
    "                        print(\"cannot create image for\", filename)\n",
    "                        failcounter = failcounter + 1\n",
    "        \n",
    "                    # remove the underscore in the filename\n",
    "                    os.rename(viewpath+\"/\"+filename, viewpath+\"/\"+filename.replace(\"_\",\"\"))\n",
    "                    \n",
    "    print (failcounter, \"images removed for quality control\")\n",
    "    print (counter, \"images processed\")\n",
    "    end = time.time()   \n",
    "    \n",
    "    return print (\"Completed in {} minutes.\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e0463-4fc9-429f-8c29-4cef1bd61a26",
   "metadata": {},
   "source": [
    "# Prepare a CSV file for the OWG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf7650-d292-4a0c-8dc9-d0ac4ebfe4da",
   "metadata": {},
   "source": [
    "This notebook contains code as a function and a walk through for creating a csv file that can be use in optical wave gauging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a017fe1-1ea9-4c2a-aae4-4fe4e842d2d8",
   "metadata": {},
   "source": [
    "\n",
    "## Read data\n",
    "\n",
    "Data comes from two sources:  \n",
    "* 1. NDBC standard meteorlogical observation archives, found [here](https://www.ndbc.noaa.gov/) \n",
    "* 2. Archived ReCON imagery, partial records can be scraped from the [website](https://www.glerl.noaa.gov/metdata/) or accessed from GLERL's network. These images should have been processed by the prepowgimgs function\n",
    "\n",
    "\n",
    "This data must be joined so that each webcam image is associated with the meterological observations taken no later than 30 minutes before or after the image was captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fbeabe-17c5-461a-8ce3-8dbfdb8e130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete csv\n",
    "\n",
    "def waveframetocsv(fn, target, csvfile, directory, localtimezone):\n",
    "    '''\n",
    "    This function takes a txt file and folder of OWG images and combines the data into a csv file that can be fed into the OWG. \n",
    "    version 2.0\n",
    "    \n",
    "    fn: filename and location of .txt file\n",
    "    target: attribute that the owg will be predicting\n",
    "    csvfile:the name of the csvfile being created\n",
    "    directory: the directory of images that have been prepped for OWG filtering\n",
    "    localtimezone: the timezone code in pytz that the images were taken in\n",
    "    '''\n",
    "    \n",
    "    #counters for debugging and perfomance info\n",
    "    initaladdcounter = 0\n",
    "    rangecounter = 0\n",
    "    successcounter = 0\n",
    "    failcounter = 0\n",
    "    timecounter = 0\n",
    "    outofrangecounter = 0\n",
    "    \n",
    "    # create a dataframe from the buoy data\n",
    "    df = pd.read_csv(fn, skiprows=range(1,2), delim_whitespace = True, \\\n",
    "                    parse_dates={'date':[0,1,2,3,4]}, keep_date_col=False)\n",
    "\n",
    "    # Transfer data in \"date\" column to a column where it is stored as a datetime object\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format = '%Y %m %d %H %M',utc=True)\n",
    "    df = df.drop(df.columns[[0,1,2,3,6,8,9,10,11,12, 13]], axis = 1)\n",
    "    \n",
    "    # calculate unix datetime\n",
    "    df['epoch']=(df['datetime'] - pd.Timestamp(\"1970-01-01\",tz='utc')) // pd.Timedelta('1s')\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    # delete the csv file if it exsists\n",
    "    try:\n",
    "        print (\"Overwriting csv file\")\n",
    "        os.remove(csvfile)\n",
    "        owgframe = pd.DataFrame({\"id\":[], \"H\":[], \"T\":[], \"MWDIR\":[]})\n",
    "    except:\n",
    "        print(\"couldn't find file, making new one\")\n",
    "        # create csv file that will be appended to by loop\n",
    "        owgframe = pd.DataFrame({\"id\":[], \"H\":[], \"T\":[], \"MWDIR\":[]})\n",
    "\n",
    "    #loop through directory and extract unix timestamp\n",
    "    for filename in os.listdir(directory):\n",
    "        # Use string slicing to remove .jpg from filename\n",
    "        size = len(filename)\n",
    "        fn = filename[:size - 4]\n",
    "       \n",
    "        \n",
    "        #get utc time from filename\n",
    "        local = pytz.timezone(localtimezone)\n",
    "        naive = datetime.datetime.strptime(fn, \"%Y%m%d%H%M\")\n",
    "        local_dt = local.localize(naive)\n",
    "        utc_dt = local_dt.astimezone(pytz.utc)\n",
    "        utime = calendar.timegm(utc_dt.timetuple())\n",
    "        \n",
    "        # combine datasets\n",
    "        try:\n",
    "            # track if buoy was in the water when the image was taken and find the closest record\n",
    "            if utime >= df['epoch'].iat[0]:\n",
    "                result_index = df['epoch'].sub(utime).abs().idxmin()\n",
    "                result = df['epoch'].iat[result_index]\n",
    "                rangecounter = rangecounter + 1\n",
    "                \n",
    "                # determine if the closest record was within 30 minutes and add to final dataframe\n",
    "                if abs(utime - result) <= 1800:\n",
    "                    initaladdcounter = initaladdcounter + 1\n",
    "                    stageframe = {\"id\":filename, \"H\": df['WVHT'].iat[result_index], \"T\": df['DPD'].iat[result_index], \"MWDIR\":df['MWD'].iat[result_index]}\n",
    "                    owgframe = owgframe.append(stageframe, ignore_index = True)\n",
    "                    \n",
    "                    # drop NAN values for the target variable\n",
    "                    if target == \"WVHT\":\n",
    "                        owgframe = owgframe[owgframe.H != 99.0]\n",
    "                    if target == \"DPD\":\n",
    "                        owgframe = owgframe[owgframe.DPD != 99.0]\n",
    "                    if target == \"MWD\":\n",
    "                        owgframe = owgframe[owgframe.MWDIR != 999]\n",
    "                else:\n",
    "                    timecounter = timecounter + 1\n",
    "            else:\n",
    "                outofrangecounter = outofrangecounter + 1\n",
    "        except:\n",
    "            failcounter = failcounter + 1\n",
    "    \n",
    "    # write final dataframe to csv\n",
    "    added = len(owgframe.index)\n",
    "    owgframe.to_csv(csvfile, index = False)    \n",
    "    \n",
    "    # display performance information\n",
    "    print (\"you have {} images during buoy deployment\".format(rangecounter))\n",
    "    print (\"{} images outside of buoy deployment\".format(outofrangecounter))\n",
    "    print (\"{} images do not have data within 30 minutes\".format(timecounter))\n",
    "    print (\"{} images had NAN data from buoy\".format(initaladdcounter-int(added)))\n",
    "    print (\"{} images failed\".format(failcounter))\n",
    "    print (\"{} images added to {}\".format(added, csvfile))\n",
    "    \n",
    "   \n",
    "    \n",
    "    return  \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88308638-6d0c-40ae-af7a-0d78275856fe",
   "metadata": {},
   "source": [
    "\n",
    "### Run function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d091f535-449b-4b14-850e-ae6785a4e591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.41   2.68   24 2021-05-08 22:00:00+00:00  1620511200\n",
      "1      0.39   2.78   63 2021-05-08 22:10:00+00:00  1620511800\n",
      "2      0.39   2.45   65 2021-05-08 22:20:00+00:00  1620512400\n",
      "3      0.36   2.62   84 2021-05-08 22:30:00+00:00  1620513000\n",
      "4      0.34   2.73   86 2021-05-08 22:40:00+00:00  1620513600\n",
      "...     ...    ...  ...                       ...         ...\n",
      "20897  0.28   2.11  224 2021-10-14 11:30:00+00:00  1634211000\n",
      "20898  0.27   2.33  217 2021-10-14 11:40:00+00:00  1634211600\n",
      "20899  0.25   2.32  215 2021-10-14 11:50:00+00:00  1634212200\n",
      "20900  0.23   2.34  227 2021-10-14 12:10:00+00:00  1634213400\n",
      "20901  0.23  99.00  216 2021-10-14 12:20:00+00:00  1634214000\n",
      "\n",
      "[20902 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 1130 images during buoy deployment\n",
      "412 images outside of buoy deployment\n",
      "45 images do not have data within 30 minutes\n",
      "43 images had NAN data from buoy\n",
      "0 images failed\n",
      "1042 images added to C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2021\"\n",
    "waveframetocsv(fn, target, csvfile, directory, \"America/Chicago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d331d-d949-4b57-a342-4a1c425031ca",
   "metadata": {},
   "source": [
    "This shows not only a huge increase in available data per trial, but also ensures much more accurate and higher quality data which can only better serve model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68536057-589b-4a76-9789-f0af8113daba",
   "metadata": {},
   "source": [
    "\n",
    "### Merging multiple datasets \n",
    "\n",
    "If you want to use multiple years, you will need to merge the csv files together with the below function before continuing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e95b75ab-1833-4b16-bd37-3250ec189b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeyears(csv_directory, startswith, mergedcsv):\n",
    "    ''' Merges multiple csv files together into one cohesive dataset that can be used for optical wave gauging. \n",
    "    csv file names must have identical beginnings for this function to work. \n",
    "    \n",
    "    csv_direcotry: folder with all target csv files\n",
    "    startswith: string that comprises the beginning of all target file names\n",
    "    mergedcsv: name of the csv file to be created '''\n",
    "    \n",
    "    filelist = [csv_directory + file for file in os.listdir(csv_directory) if file.startswith(startswith)]\n",
    "    csv_list = []\n",
    "    for file in sorted(filelist):\n",
    "        csv_list.append(pd.read_csv(file, sep = \",\"))\n",
    "    csv_merged = pd.concat(csv_list, ignore_index = True)\n",
    "    \n",
    "    csv_merged.to_csv(csv_directory + mergedcsv, index = False)\n",
    "    \n",
    "    return print (\"csv with {} rows created\".format(len(csv_merged)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4edbb-13ef-44fb-99f3-ab0b1139b2e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Code for creating model assessment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319ee778-e0b1-4848-abd5-d1ec4a1932e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ran(csv, sample_csv, sample_percent):\n",
    "    ''' This function selects for a percentage of random rows in the csv training dataset \n",
    "    and creates a new csv for model assessment while dropping them from the original csv\n",
    "    \n",
    "    csv : Path to the csv that the function initially reads\n",
    "    validation_csv : Path and name of the csv to be created from csv\n",
    "    sample_percent : decimal value of the percentage of rows to be sampled '''\n",
    "    \n",
    "    if os.path.exists(sample_csv) == True:\n",
    "        return print (\"File already exists\")\n",
    "    else:    \n",
    "        # open csv as a pandas dataframe \n",
    "        df = pd.read_csv(csv, sep = \",\")\n",
    "        # randomly sample data\n",
    "        df_sample = df.sample(n = int(sample_percent * len(df.index)))\n",
    "        # drop data from original dataframe that has been sampled\n",
    "        df = df[~df.id.isin(df_sample.id)]\n",
    "   \n",
    "        # export dataframes as csv files\n",
    "        df.to_csv(csv, sep = \",\", index = False) \n",
    "        df_sample.to_csv(sample_csv, sep = \",\", index = False)\n",
    "        print (\"writing {}\".format(sample_csv))\n",
    "    \n",
    "        return print (\"{}% of {} ({} rows) sampled\".format(sample_percent*100, csv, len(df_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7302b03c-f716-412e-9ec9-e98a30e72733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "csv = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype.csv\"\n",
    "sample_csv = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021_prototype(sample).csv\"\n",
    "sample_percent = .3\n",
    "sample_ran(csv, sample_csv, sample_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4082e7d-61f8-40fd-944b-6bdb0e1c9cc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder\n",
      "Moving Files\n",
      "Seperating View 1\n",
      "Seperating View 2\n",
      "Moving images to D:/ReCON_imgs/2017/mcy/2017_imgprepglerl1/view1\n",
      "Augmenting and filtering imgaes in D:/ReCON_imgs/2017/mcy/2017_imgprepglerl1/view1\n",
      "Moving images to D:/ReCON_imgs/2017/mcy/2017_imgprepglerl1/view2\n",
      "Augmenting and filtering imgaes in D:/ReCON_imgs/2017/mcy/2017_imgprepglerl1/view2\n",
      "1854 images removed for quality control\n",
      "5555 images processed\n",
      "Completed in 6.037659668922425 minutes.\n"
     ]
    }
   ],
   "source": [
    "year = 2017\n",
    "directory = \"D:/ReCON_imgs/2017/mcy\"\n",
    "arrayshape =  np.index_exp[100:700, 680:1280]\n",
    "resolution = 512 \n",
    "trial = \"glerl1\" \n",
    "viewlist = [1,2]\n",
    "\n",
    "prepowgimgs(year, directory, arrayshape, resolution, trial, viewlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4a5aa4-df1d-4bbd-a751-e614b1fa3e45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.41   2.68   24 2021-05-08 22:00:00+00:00  1620511200\n",
      "1      0.39   2.78   63 2021-05-08 22:10:00+00:00  1620511800\n",
      "2      0.39   2.45   65 2021-05-08 22:20:00+00:00  1620512400\n",
      "3      0.36   2.62   84 2021-05-08 22:30:00+00:00  1620513000\n",
      "4      0.34   2.73   86 2021-05-08 22:40:00+00:00  1620513600\n",
      "...     ...    ...  ...                       ...         ...\n",
      "20897  0.28   2.11  224 2021-10-14 11:30:00+00:00  1634211000\n",
      "20898  0.27   2.33  217 2021-10-14 11:40:00+00:00  1634211600\n",
      "20899  0.25   2.32  215 2021-10-14 11:50:00+00:00  1634212200\n",
      "20900  0.23   2.34  227 2021-10-14 12:10:00+00:00  1634213400\n",
      "20901  0.23  99.00  216 2021-10-14 12:20:00+00:00  1634214000\n",
      "\n",
      "[20902 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2562 images during buoy deployment\n",
      "412 images outside of buoy deployment\n",
      "513 images do not have data within 30 minutes\n",
      "77 images had NAN data from buoy\n",
      "0 images failed\n",
      "1972 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2021.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2021.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2021.csv\"\n",
    "directory = \"C:/njc/misc/mcy/2021_imgprepglerl1/view2\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a231631d-4990-461d-a87b-2fa85b4ccb83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      WVHT    DPD  MWD                  datetime       epoch\n",
      "0     0.59  99.00  999 2020-06-15 20:00:00+00:00  1592251200\n",
      "1     0.66  99.00  999 2020-06-15 20:10:00+00:00  1592251800\n",
      "2     0.66  99.00  299 2020-06-15 20:20:00+00:00  1592252400\n",
      "3     0.70  99.00  999 2020-06-15 20:30:00+00:00  1592253000\n",
      "4     0.63   7.82   20 2020-06-15 20:50:00+00:00  1592254200\n",
      "...    ...    ...  ...                       ...         ...\n",
      "6488  0.66   3.30  120 2020-08-14 04:10:00+00:00  1597378200\n",
      "6489  0.66   3.38   41 2020-08-14 04:20:00+00:00  1597378800\n",
      "6490  0.67   3.38  999 2020-08-14 04:30:00+00:00  1597379400\n",
      "6491  0.74   3.38  999 2020-08-14 04:40:00+00:00  1597380000\n",
      "6492  0.78   3.38   41 2020-08-14 04:50:00+00:00  1597380600\n",
      "\n",
      "[6493 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 1150 images during buoy deployment\n",
      "1311 images outside of buoy deployment\n",
      "708 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "442 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2020.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2020.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2020.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2020\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69595958-6916-4a94-bf92-1d05b139b40c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.00  99.00  999 2019-04-02 19:00:00+00:00  1554231600\n",
      "1      0.00   5.45   67 2019-04-02 19:10:00+00:00  1554232200\n",
      "2      0.00   6.83  235 2019-04-02 19:20:00+00:00  1554232800\n",
      "3      0.46   2.41  191 2019-04-17 23:00:00+00:00  1555542000\n",
      "4      0.45   2.39  206 2019-04-17 23:10:00+00:00  1555542600\n",
      "...     ...    ...  ...                       ...         ...\n",
      "28512  0.48   2.21   41 2019-11-06 15:20:00+00:00  1573053600\n",
      "28513  0.49   2.21   77 2019-11-06 15:30:00+00:00  1573054200\n",
      "28514  0.51   2.21  118 2019-11-06 15:40:00+00:00  1573054800\n",
      "28515  0.51   2.26  212 2019-11-06 15:50:00+00:00  1573055400\n",
      "28516  0.48   2.38  192 2019-11-06 16:00:00+00:00  1573056000\n",
      "\n",
      "[28517 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2160 images during buoy deployment\n",
      "201 images outside of buoy deployment\n",
      "461 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "1699 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2019.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2019.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2019.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2019\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7de5b3-0b55-42cc-999e-54a29d2470a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.26   4.13   95 2018-05-07 20:20:00+00:00  1525724400\n",
      "1      0.25   4.03  343 2018-05-07 20:30:00+00:00  1525725000\n",
      "2      0.25   4.08  329 2018-05-07 20:40:00+00:00  1525725600\n",
      "3      0.25   4.10   12 2018-05-07 20:50:00+00:00  1525726200\n",
      "4      0.25   4.15  206 2018-05-07 21:00:00+00:00  1525726800\n",
      "...     ...    ...  ...                       ...         ...\n",
      "25649  0.71   3.47  292 2018-11-05 17:10:00+00:00  1541437800\n",
      "25650  0.45   3.47  999 2018-11-05 17:20:00+00:00  1541438400\n",
      "25651  0.00  99.00  999 2018-11-09 20:20:00+00:00  1541794800\n",
      "25652  0.01   7.01   64 2018-11-09 20:30:00+00:00  1541795400\n",
      "25653  0.00  99.00  999 2018-11-09 21:30:00+00:00  1541799000\n",
      "\n",
      "[25654 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2198 images during buoy deployment\n",
      "1308 images outside of buoy deployment\n",
      "222 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "1976 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2018.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2018.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2018.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2018\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192f0980-884a-4219-ac95-021f124b2c75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.01  11.64  999 2017-04-19 18:10:00+00:00  1492625400\n",
      "1      0.01  99.00  999 2017-04-19 18:20:00+00:00  1492626000\n",
      "2      0.01  12.15   45 2017-04-19 18:30:00+00:00  1492626600\n",
      "3      0.01  10.41   40 2017-04-19 18:40:00+00:00  1492627200\n",
      "4      0.01   6.58  227 2017-04-19 18:50:00+00:00  1492627800\n",
      "...     ...    ...  ...                       ...         ...\n",
      "27893  0.70   2.29   66 2017-11-11 17:00:00+00:00  1510419600\n",
      "27894  0.92   2.29  999 2017-11-11 17:10:00+00:00  1510420200\n",
      "27895  0.91   2.29  999 2017-11-11 17:20:00+00:00  1510420800\n",
      "27896  0.72   2.29   61 2017-11-11 17:30:00+00:00  1510421400\n",
      "27897  0.42   2.29  263 2017-11-11 17:40:00+00:00  1510422000\n",
      "\n",
      "[27898 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2601 images during buoy deployment\n",
      "498 images outside of buoy deployment\n",
      "521 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "2080 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_201.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2017.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2017.csv\"\n",
    "directory = \"D:/ReCON_imgs/2017/mcy/2017_imgprepglerl1/view2\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e04840-eafb-4096-b545-c55a3d0cfdbc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.00  99.00  999 2016-05-06 14:10:00+00:00  1462543800\n",
      "1      0.00   8.26  999 2016-05-06 14:20:00+00:00  1462544400\n",
      "2      0.01  10.45  999 2016-05-06 14:30:00+00:00  1462545000\n",
      "3      0.01  12.76  999 2016-05-06 14:40:00+00:00  1462545600\n",
      "4      0.01  10.75  312 2016-05-06 14:50:00+00:00  1462546200\n",
      "...     ...    ...  ...                       ...         ...\n",
      "25051  0.40   3.96  999 2016-11-01 17:00:00+00:00  1478019600\n",
      "25052  0.41   4.40   70 2016-11-01 17:10:00+00:00  1478020200\n",
      "25053  0.44   4.40  208 2016-11-01 17:20:00+00:00  1478020800\n",
      "25054  0.39   5.63  267 2016-11-01 17:30:00+00:00  1478021400\n",
      "25055  0.27   4.76  284 2016-11-01 17:40:00+00:00  1478022000\n",
      "\n",
      "[25056 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2175 images during buoy deployment\n",
      "163 images outside of buoy deployment\n",
      "370 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "1805 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2016.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2016.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2016.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2016\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d8eec4-157f-4978-8410-a6053c07597d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.02  99.00  999 2015-04-16 16:00:00+00:00  1429200000\n",
      "1      0.01   5.89  244 2015-04-16 16:10:00+00:00  1429200600\n",
      "2      0.01   5.89   81 2015-04-16 16:20:00+00:00  1429201200\n",
      "3      0.01   6.55   13 2015-04-16 16:30:00+00:00  1429201800\n",
      "4      0.01   6.55  999 2015-04-16 16:40:00+00:00  1429202400\n",
      "...     ...    ...  ...                       ...         ...\n",
      "28406  0.31   2.71  241 2015-11-02 18:30:00+00:00  1446489000\n",
      "28407  0.33   2.71  999 2015-11-02 18:40:00+00:00  1446489600\n",
      "28408  0.35   2.80  271 2015-11-02 18:50:00+00:00  1446490200\n",
      "28409  0.50   2.80  999 2015-11-02 19:00:00+00:00  1446490800\n",
      "28410  0.54   2.80  999 2015-11-02 19:10:00+00:00  1446491400\n",
      "\n",
      "[28411 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 2076 images during buoy deployment\n",
      "90 images outside of buoy deployment\n",
      "579 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "1497 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2015.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2015.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2015.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2015\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b67c6de-5138-4351-94ed-723de64c0a06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT   DPD  MWD                  datetime       epoch\n",
      "0      0.28  3.44    2 2014-06-10 14:40:00+00:00  1402411200\n",
      "1      0.30  3.26   10 2014-06-10 14:50:00+00:00  1402411800\n",
      "2      0.29  3.17    4 2014-06-10 15:00:00+00:00  1402412400\n",
      "3      0.30  3.15   11 2014-06-10 15:10:00+00:00  1402413000\n",
      "4      0.28  3.21  353 2014-06-10 15:20:00+00:00  1402413600\n",
      "...     ...   ...  ...                       ...         ...\n",
      "17463  0.96  1.75  999 2014-10-10 15:50:00+00:00  1412956200\n",
      "17464  0.95  1.75  999 2014-10-10 16:00:00+00:00  1412956800\n",
      "17465  1.05  1.75  343 2014-10-10 16:10:00+00:00  1412957400\n",
      "17466  1.12  1.75  999 2014-10-10 16:20:00+00:00  1412958000\n",
      "17467  2.07  1.75  999 2014-10-10 16:30:00+00:00  1412958600\n",
      "\n",
      "[17468 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 694 images during buoy deployment\n",
      "672 images outside of buoy deployment\n",
      "149 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "545 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2014.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2014.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2014.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2014\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ba3a61-e82e-41fa-9d4c-177e7e733944",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT    DPD  MWD                  datetime       epoch\n",
      "0      0.41  99.00  273 2013-06-01 00:00:00+00:00  1370044800\n",
      "1      0.37   2.02  182 2013-06-01 00:10:00+00:00  1370045400\n",
      "2      0.33   2.12  199 2013-06-01 00:20:00+00:00  1370046000\n",
      "3      0.29   2.12   -1 2013-06-01 00:30:00+00:00  1370046600\n",
      "4      0.28   2.12   -1 2013-06-01 00:40:00+00:00  1370047200\n",
      "...     ...    ...  ...                       ...         ...\n",
      "21723  0.12  99.00  139 2013-10-30 17:50:00+00:00  1383155400\n",
      "21724  0.25  99.00  134 2013-10-30 18:00:00+00:00  1383156000\n",
      "21725  0.47  99.00  188 2013-10-30 18:10:00+00:00  1383156600\n",
      "21726  0.42  99.00  330 2013-10-30 18:20:00+00:00  1383157200\n",
      "21727  0.01  99.00   -1 2013-10-30 18:30:00+00:00  1383157800\n",
      "\n",
      "[21728 rows x 5 columns]\n",
      "Overwriting csv file\n",
      "couldn't find file, making new one\n",
      "you have 1288 images during buoy deployment\n",
      "0 images outside of buoy deployment\n",
      "309 images do not have data within 30 minutes\n",
      "0 images had NAN data from buoy\n",
      "0 images failed\n",
      "979 images added to C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2013.csv\n"
     ]
    }
   ],
   "source": [
    "fn = \"C:/njc/src/GLERL_contract/buoy_data/mcy2013.txt\"\n",
    "target = \"WVHT\"\n",
    "csvfile = \"C:/njc/src/GLERL_contract/buoy_data/mcy_glerl1_2013.csv\"\n",
    "directory = \"D:/ReCON_imgs/mcy_total/2013\"\n",
    "localtimezone = \"America/Chicago\"\n",
    "waveframetocsv(fn, target, csvfile, directory, localtimezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14bdb97d-619b-4db1-9972-09cc07c25ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv with 12995 rows created\n"
     ]
    }
   ],
   "source": [
    "csv_directory = \"c:/njc/src/GLERL_contract/buoy_data/\"\n",
    "startswith = \"mcy_glerl1_\"\n",
    "mergedcsv = \"owg_glerl1.csv\"\n",
    "mergeyears(csv_directory, startswith, mergedcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ca454bd-7444-42b7-bf74-3338598d711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing C:/njc/src/GLERL_contract/buoy_data/owg_glerl1_test30.csv\n",
      "30.0% of C:/njc/src/GLERL_contract/buoy_data/owg_glerl1.csv (2729 rows) sampled\n"
     ]
    }
   ],
   "source": [
    "csv = \"C:/njc/src/GLERL_contract/buoy_data/owg_glerl1.csv\"\n",
    "sample_csv = \"C:/njc/src/GLERL_contract/buoy_data/owg_glerl1_test30.csv\"\n",
    "sample_percent = .3\n",
    "sample_ran(csv, sample_csv, sample_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
